---
title: 操作系统概念总览
type: tags
tags:
  - null
date: 2019-02-14 15:47:14
categories:
description:
---

​	进程之间的资源不共享，是系统分配资源的基本单位，因此不能够创建多个进程去进行并行处理一个文件。共享内存是另一种



线程无法利用时钟强制中断线程让出cpu，需要使用线程调用therd_yield，通过编程解决



# 二、进程管理

## 进程与线程

### 1. 进程

进程是资源分配的基本单位。

进程控制块 (Process Control Block, PCB) 描述进程的基本信息和运行状态，所谓的创建进程和撤销进程，都是指对 PCB 的操作。

下图显示了 4 个程序创建了 4 个进程，这 4 个进程可以并发地执行。

[![img](https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/a6ac2b08-3861-4e85-baa8-382287bfee9f.png)](https://github.com/CyC2018/CS-Notes/blob/master/docs/notes/pics/a6ac2b08-3861-4e85-baa8-382287bfee9f.png)

### 2. 线程

线程是独立调度的基本单位。

一个进程中可以有多个线程，它们共享进程资源。

QQ 和浏览器是两个进程，浏览器进程里面有很多线程，例如 HTTP 请求线程、事件响应线程、渲染线程等等，线程的并发执行使得在浏览器中点击一个新链接从而发起 HTTP 请求时，浏览器还可以响应用户的其它事件。

[![img](https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/3cd630ea-017c-488d-ad1d-732b4efeddf5.png)](https://github.com/CyC2018/CS-Notes/blob/master/docs/notes/pics/3cd630ea-017c-488d-ad1d-732b4efeddf5.png)

### 3. 区别

Ⅰ 拥有资源

进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源。

Ⅱ 调度

线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。

Ⅲ 系统开销

由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。

Ⅳ 通信方面

线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助 IPC。

## 进程状态的切换

[![img](https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/ProcessState.png)](https://github.com/CyC2018/CS-Notes/blob/master/docs/notes/pics/ProcessState.png)

- 就绪状态（ready）：等待被调度
- 运行状态（running）
- 阻塞状态（waiting）：等待资源

应该注意以下内容：

- 只有就绪态和运行态可以相互转换，其它的都是单向转换。就绪状态的进程通过调度算法从而获得 CPU 时间，转为运行状态；而运行状态的进程，在分配给它的 CPU 时间片用完之后就会转为就绪状态，等待下一次调度。
- 阻塞状态是缺少需要的资源从而由运行状态转换而来，但是该资源不包括 CPU 时间，缺少 CPU 时间会从运行态转换为就绪态。

## 进程调度

​	当多个进程或线程处于就绪状态，对CPU的资源进行竞争，选择下一个要运行的进程，即调度

**进程切换代价**

- 用户态必须切换到内核态，保存当前进程的状态，内存映像也需要保存
- 将新进程的内存映像装入MMU，新进程开始运行
- 整个内存的高速缓存失效，强迫缓存从内存中动态重新装入两次（进入内核、离开内核）

**进程行为**

​	计算密集型进程：具有较长时间的CPU集中使用与较短的IO等待

​	IO密集型进程：具有较短时间的CPU集中使用与频繁的IO等待，（IO调度更为重要）

​	在IO开始后无论处理数据是多还是少，必须花费同样的时间提出硬件请求读取磁盘块。更多的进程开始倾向为IO密集型，因为CPU的改进比磁盘更快。如果需要运行IO密集型进程，就应该让它尽早得到机会，以便使得磁盘始终忙碌。

**调度算法**

​	不同环境的调度算法目标不同，因此需要针对不同环境来讨论调度算法。

### 1. 批处理系统

批处理系统没有太多的用户操作，在该系统中，调度算法目标是保证吞吐量和周转时间（从提交到终止的时间）。

**1.1 先来先服务 first-come first-serverd（FCFS）**

按照请求的顺序进行调度。

有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。

**1.2 短作业优先 shortest job first（SJF）**

按估计运行时间最短的顺序进行调度。

长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。

**1.3 最短剩余时间优先 shortest remaining time next（SRTN）**

按估计剩余时间最短的顺序进行调度。

### 2. 交互式系统

交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。

**2.1 时间片轮转**

将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。

时间片轮转算法的效率和时间片的大小有很大关系：

- 因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。
- 而如果时间片过长，那么实时性就不能得到保证。

[![img](https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/8c662999-c16c-481c-9f40-1fdba5bc9167.png)](https://github.com/CyC2018/CS-Notes/blob/master/docs/notes/pics/8c662999-c16c-481c-9f40-1fdba5bc9167.png)

**2.2 优先级调度**

为每个进程分配一个优先级，按优先级进行调度。

为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。

**2.3 多级反馈队列**

一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。

多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换 7 次。

每个队列优先权也不同，最上面的优先权最高。因此只有上一个队列没有进程在排队，才能调度当前队列上的进程。

可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。

[![img](https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/042cf928-3c8e-4815-ae9c-f2780202c68f.png)](https://github.com/CyC2018/CS-Notes/blob/master/docs/notes/pics/042cf928-3c8e-4815-ae9c-f2780202c68f.png)

### 3. 实时系统

实时系统要求一个请求在一个确定时间内得到响应。

分为硬实时和软实时，前者必须满足绝对的截止时间，后者可以容忍一定的超时。

## 进程同步

### 1. 临界区

对临界资源进行访问的那段代码称为临界区。

为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查。

```
// entry section
// critical section;
// exit section
```

### 2. 同步与互斥

- 同步：多个进程按一定顺序执行；
- 互斥：多个进程在同一时刻只有一个进程能进入临界区。

### 3. 信号量

信号量（Semaphore）是一个整型变量，可以对其执行 down 和 up 操作，也就是常见的 P 和 V 操作。

- **down** : 如果信号量大于 0 ，执行 -1 操作；如果信号量等于 0，进程睡眠，等待信号量大于 0；
- **up** ：对信号量执行 +1 操作，唤醒睡眠的进程让其完成 down 操作。

down 和 up 操作需要被设计成原语，不可分割，通常的做法是在执行这些操作的时候屏蔽中断。

如果信号量的取值只能为 0 或者 1，那么就成为了 **互斥量（Mutex）** ，0 表示临界区已经加锁，1 表示临界区解锁。

```
typedef int semaphore;
semaphore mutex = 1;
void P1() {
    down(&mutex);
    // 临界区
    up(&mutex);
}

void P2() {
    down(&mutex);
    // 临界区
    up(&mutex);
}
```

**使用信号量实现生产者-消费者问题** 

问题描述：使用一个缓冲区来保存物品，只有缓冲区没有满，生产者才可以放入物品；只有缓冲区不为空，消费者才可以拿走物品。

因为缓冲区属于临界资源，因此需要使用一个互斥量 mutex 来控制对缓冲区的互斥访问。

为了同步生产者和消费者的行为，需要记录缓冲区中物品的数量。数量可以使用信号量来进行统计，这里需要使用两个信号量：empty 记录空缓冲区的数量，full 记录满缓冲区的数量。其中，empty 信号量是在生产者进程中使用，当 empty 不为 0 时，生产者才可以放入物品；full 信号量是在消费者进程中使用，当 full 信号量不为 0 时，消费者才可以取走物品。

注意，不能先对缓冲区进行加锁，再测试信号量。也就是说，不能先执行 down(mutex) 再执行 down(empty)。如果这么做了，那么可能会出现这种情况：生产者对缓冲区加锁后，执行 down(empty) 操作，发现 empty = 0，此时生产者睡眠。消费者不能进入临界区，因为生产者对缓冲区加锁了，消费者就无法执行 up(empty) 操作，empty 永远都为 0，导致生产者永远等待下，不会释放锁，消费者因此也会永远等待下去。

```
#define N 100
typedef int semaphore;
semaphore mutex = 1;
semaphore empty = N;
semaphore full = 0;

void producer() {
    while(TRUE) {
        int item = produce_item();
        down(&empty);
        down(&mutex);
        insert_item(item);
        up(&mutex);
        up(&full);
    }
}

void consumer() {
    while(TRUE) {
        down(&full);
        down(&mutex);
        int item = remove_item();
        consume_item(item);
        up(&mutex);
        up(&empty);
    }
}
```

### 4. 管程

使用信号量机制实现的生产者消费者问题需要客户端代码做很多控制，而管程把控制的代码独立出来，不仅不容易出错，也使得客户端代码调用更容易。

c 语言不支持管程，下面的示例代码使用了类 Pascal 语言来描述管程。示例代码的管程提供了 insert() 和 remove() 方法，客户端代码通过调用这两个方法来解决生产者-消费者问题。

```
monitor ProducerConsumer
    integer i;
    condition c;

    procedure insert();
    begin
        // ...
    end;

    procedure remove();
    begin
        // ...
    end;
end monitor;
```

管程有一个重要特性：在一个时刻只能有一个进程使用管程。进程在无法继续执行的时候不能一直占用管程，否者其它进程永远不能使用管程。

管程引入了 **条件变量** 以及相关的操作：**wait()** 和 **signal()** 来实现同步操作。对条件变量执行 wait() 操作会导致调用进程阻塞，把管程让出来给另一个进程持有。signal() 操作用于唤醒被阻塞的进程。

**使用管程实现生产者-消费者问题** 

```
// 管程
monitor ProducerConsumer
    condition full, empty;
    integer count := 0;
    condition c;

    procedure insert(item: integer);
    begin
        if count = N then wait(full);
        insert_item(item);
        count := count + 1;
        if count = 1 then signal(empty);
    end;

    function remove: integer;
    begin
        if count = 0 then wait(empty);
        remove = remove_item;
        count := count - 1;
        if count = N -1 then signal(full);
    end;
end monitor;

// 生产者客户端
procedure producer
begin
    while true do
    begin
        item = produce_item;
        ProducerConsumer.insert(item);
    end
end;

// 消费者客户端
procedure consumer
begin
    while true do
    begin
        item = ProducerConsumer.remove;
        consume_item(item);
    end
end;
```

## 经典同步问题

生产者和消费者问题前面已经讨论过了。

### 1. 读者-写者问题

允许多个进程同时对数据进行读操作，但是不允许读和写以及写和写操作同时发生。

一个整型变量 count 记录在对数据进行读操作的进程数量，一个互斥量 count_mutex 用于对 count 加锁，一个互斥量 data_mutex 用于对读写的数据加锁。

```
typedef int semaphore;
semaphore count_mutex = 1;
semaphore data_mutex = 1;
int count = 0;

void reader() {
    while(TRUE) {
        down(&count_mutex);
        count++;
        if(count == 1) down(&data_mutex); // 第一个读者需要对数据进行加锁，防止写进程访问
        up(&count_mutex);
        read();
        down(&count_mutex);
        count--;
        if(count == 0) up(&data_mutex);
        up(&count_mutex);
    }
}

void writer() {
    while(TRUE) {
        down(&data_mutex);
        write();
        up(&data_mutex);
    }
}
```

以下内容由 [@Bandi Yugandhar](https://github.com/yugandharbandi) 提供。

The first case may result Writer to starve. This case favous Writers i.e no writer, once added to the queue, shall be kept waiting longer than absolutely necessary(only when there are readers that entered the queue before the writer).

```
int readcount, writecount;                   //(initial value = 0)
semaphore rmutex, wmutex, readLock, resource; //(initial value = 1)

//READER
void reader() {
<ENTRY Section>
 down(&readLock);                 //  reader is trying to enter
 down(&rmutex);                  //   lock to increase readcount
  readcount++;                 
  if (readcount == 1)          
   down(&resource);              //if you are the first reader then lock  the resource
 up(&rmutex);                  //release  for other readers
 up(&readLock);                 //Done with trying to access the resource

<CRITICAL Section>
//reading is performed

<EXIT Section>
 down(&rmutex);                  //reserve exit section - avoids race condition with readers
 readcount--;                       //indicate you're leaving
  if (readcount == 0)          //checks if you are last reader leaving
   up(&resource);              //if last, you must release the locked resource
 up(&rmutex);                  //release exit section for other readers
}

//WRITER
void writer() {
  <ENTRY Section>
  down(&wmutex);                  //reserve entry section for writers - avoids race conditions
  writecount++;                //report yourself as a writer entering
  if (writecount == 1)         //checks if you're first writer
   down(&readLock);               //if you're first, then you must lock the readers out. Prevent them from trying to enter CS
  up(&wmutex);                  //release entry section

<CRITICAL Section>
 down(&resource);                //reserve the resource for yourself - prevents other writers from simultaneously editing the shared resource
  //writing is performed
 up(&resource);                //release file

<EXIT Section>
  down(&wmutex);                  //reserve exit section
  writecount--;                //indicate you're leaving
  if (writecount == 0)         //checks if you're the last writer
   up(&readLock);               //if you're last writer, you must unlock the readers. Allows them to try enter CS for reading
  up(&wmutex);                  //release exit section
}
```

We can observe that every reader is forced to acquire ReadLock. On the otherhand, writers doesn’t need to lock individually. Once the first writer locks the ReadLock, it will be released only when there is no writer left in the queue.

From the both cases we observed that either reader or writer has to starve. Below solutionadds the constraint that no thread shall be allowed to starve; that is, the operation of obtaining a lock on the shared data will always terminate in a bounded amount of time.

```
int readCount;                  // init to 0; number of readers currently accessing resource

// all semaphores initialised to 1
Semaphore resourceAccess;       // controls access (read/write) to the resource
Semaphore readCountAccess;      // for syncing changes to shared variable readCount
Semaphore serviceQueue;         // FAIRNESS: preserves ordering of requests (signaling must be FIFO)

void writer()
{ 
    down(&serviceQueue);           // wait in line to be servicexs
    // <ENTER>
    down(&resourceAccess);         // request exclusive access to resource
    // </ENTER>
    up(&serviceQueue);           // let next in line be serviced

    // <WRITE>
    writeResource();            // writing is performed
    // </WRITE>

    // <EXIT>
    up(&resourceAccess);         // release resource access for next reader/writer
    // </EXIT>
}

void reader()
{ 
    down(&serviceQueue);           // wait in line to be serviced
    down(&readCountAccess);        // request exclusive access to readCount
    // <ENTER>
    if (readCount == 0)         // if there are no readers already reading:
        down(&resourceAccess);     // request resource access for readers (writers blocked)
    readCount++;                // update count of active readers
    // </ENTER>
    up(&serviceQueue);           // let next in line be serviced
    up(&readCountAccess);        // release access to readCount

    // <READ>
    readResource();             // reading is performed
    // </READ>

    down(&readCountAccess);        // request exclusive access to readCount
    // <EXIT>
    readCount--;                // update count of active readers
    if (readCount == 0)         // if there are no readers left:
        up(&resourceAccess);     // release resource access for all
    // </EXIT>
    up(&readCountAccess);        // release access to readCount
}
```

### 2. 哲学家进餐问题

[![img](https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/a9077f06-7584-4f2b-8c20-3a8e46928820.jpg)](https://github.com/CyC2018/CS-Notes/blob/master/docs/notes/pics/a9077f06-7584-4f2b-8c20-3a8e46928820.jpg)

五个哲学家围着一张圆桌，每个哲学家面前放着食物。哲学家的生活有两种交替活动：吃饭以及思考。当一个哲学家吃饭时，需要先拿起自己左右两边的两根筷子，并且一次只能拿起一根筷子。

下面是一种错误的解法，考虑到如果所有哲学家同时拿起左手边的筷子，那么就无法拿起右手边的筷子，造成死锁。

```
#define N 5

void philosopher(int i) {
    while(TRUE) {
        think();
        take(i);       // 拿起左边的筷子
        take((i+1)%N); // 拿起右边的筷子
        eat();
        put(i);
        put((i+1)%N);
    }
}
```

为了防止死锁的发生，可以设置两个条件：

- 必须同时拿起左右两根筷子；
- 只有在两个邻居都没有进餐的情况下才允许进餐。

```
#define N 5
#define LEFT (i + N - 1) % N // 左邻居
#define RIGHT (i + 1) % N    // 右邻居
#define THINKING 0
#define HUNGRY   1
#define EATING   2
typedef int semaphore;
int state[N];                // 跟踪每个哲学家的状态
semaphore mutex = 1;         // 临界区的互斥
semaphore s[N];              // 每个哲学家一个信号量

void philosopher(int i) {
    while(TRUE) {
        think();
        take_two(i);
        eat();
        put_two(i);
    }
}

void take_two(int i) {
    down(&mutex);
    state[i] = HUNGRY;
    test(i);
    up(&mutex);
    down(&s[i]);
}

void put_two(i) {
    down(&mutex);
    state[i] = THINKING;
    test(LEFT);
    test(RIGHT);
    up(&mutex);
}

void test(i) {         // 尝试拿起两把筷子
    if(state[i] == HUNGRY && state[LEFT] != EATING && state[RIGHT] !=EATING) {
        state[i] = EATING;
        up(&s[i]);
    }
}
```

## 进程通信

进程同步与进程通信很容易混淆，它们的区别在于：

- 进程同步：控制多个进程按一定顺序执行；
- 进程通信：进程间传输信息。

进程通信是一种手段，而进程同步是一种目的。也可以说，为了能够达到进程同步的目的，需要让进程进行通信，传输一些进程同步所需要的信息。

#### 1. 管道

管道是通过调用 pipe 函数创建的，fd[0] 用于读，fd[1] 用于写。

```
#include <unistd.h>
int pipe(int fd[2]);
```

它具有以下限制：

- 只支持半双工通信（单向交替传输）；
- 只能在父子进程中使用。

[![img](https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/53cd9ade-b0a6-4399-b4de-7f1fbd06cdfb.png)](https://github.com/CyC2018/CS-Notes/blob/master/docs/notes/pics/53cd9ade-b0a6-4399-b4de-7f1fbd06cdfb.png)

#### 2. FIFO

也称为命名管道，去除了管道只能在父子进程中使用的限制。

```
#include <sys/stat.h>
int mkfifo(const char *path, mode_t mode);
int mkfifoat(int fd, const char *path, mode_t mode);
```

FIFO 常用于客户-服务器应用程序中，FIFO 用作汇聚点，在客户进程和服务器进程之间传递数据。

[![img](https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/2ac50b81-d92a-4401-b9ec-f2113ecc3076.png)](https://github.com/CyC2018/CS-Notes/blob/master/docs/notes/pics/2ac50b81-d92a-4401-b9ec-f2113ecc3076.png)

#### 3. 消息队列

相比于 FIFO，消息队列具有以下优点：

- 消息队列可以独立于读写进程存在，从而避免了 FIFO 中同步管道的打开和关闭时可能产生的困难；
- 避免了 FIFO 的同步阻塞问题，不需要进程自己提供同步方法；
- 读进程可以根据消息类型有选择地接收消息，而不像 FIFO 那样只能默认地接收。

#### 4. 信号量

它是一个计数器，用于为多个进程提供对共享数据对象的访问。down与up操作

#### 5.共享存储

允许多个进程共享一个给定的存储区。因为数据不需要在进程之间复制，所以这是最快的一种 IPC。

需要使用信号量用来同步对共享存储的访问。

多个进程可以将同一个文件映射到它们的地址空间从而实现共享内存。另外 XSI 共享内存不是使用文件，而是使用使用内存的匿名段。

#### 6. 套接字

与其它通信机制不同的是，它可用于不同机器间的进程通信。

### 竞争条件

​	协作的进程可能共享一些彼此公用的存储区，最后的结果取决于进程运行的精确时序（涉及到时钟中断等原因）

### 临界区

​	用于阻止多个进程同时读写共享数据，方法便是实现互斥访问

- 屏蔽中断，当访问临界区，则屏蔽对进程的中断，该方案对于OS并不明智
- 锁变量，但是依然存在竞争条件的问题
- 严格轮换，设置值去记录轮转到可以进入临界区的进程。
- 等等



# 内存管理

分层存储器体系：

​	若干M快速、昂贵、易失的高速缓存cache,数G的速度与价格适中，易失的内存，数TB的低俗、廉价、非易失的磁盘+USB等

​	任务：有效管理内存、记录哪些内存正在使用、哪些空闲、在进程需要时分配内存，使用完释放内存。

**存储器抽象**

​	如果将物理地址暴露给进程会带来危险

- 如果用户进程可以寻址内存的每个字节，就可以很容易破坏OS

- 运行多个程序将十分困难

要保证多个程序同时处于内存并不相互影响，则需要解决两个问题：保护、重定位

​	创造一个新的内存抽象：地址空间，地址空间是一个进程可用于寻址内存的一套地址集合。每个进程有其独立的一个地址空间。

**交换技术**

​	由于内存无法保存所有的进程，因此需要对进程进行处理。有两种处理内存超载的通用方法：交换与虚拟内存。

​	交换：将一个进程完整地调入内存，使该进程运行一段时间，然后存入磁盘。

## 虚拟内存

需要运行的程序往往大到内存无法容纳，且系统必须同时支持多个程序同时运行

虚拟内存的目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。

为了更好的管理内存，操作系统将内存抽象成地址空间。每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页。这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。当程序引用到不在物理内存中的页时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的指令。

从上面的描述中可以看出，虚拟内存允许程序不用将地址空间中的每一页都映射到物理内存，也就是说一个程序不需要全部调入内存就可以运行，这使得有限的内存运行大程序成为可能。例如有一台计算机可以产生 16 位地址，那么一个程序的地址空间范围是 0~64K。该计算机只有 32KB 的物理内存，虚拟内存技术允许该计算机运行一个 64K 大小的程序。

[![img](https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/7b281b1e-0595-402b-ae35-8c91084c33c1.png)](https://github.com/CyC2018/CS-Notes/blob/master/docs/notes/pics/7b281b1e-0595-402b-ae35-8c91084c33c1.png)

**分页**

虚拟地址空间按照固定大小划分成称为页面的若干单元，在物理内存中对应的单元称为页框（一般与页面大小一致）。RAM与磁盘间的交换通常以整个页面为单元进行。

缺页中断：由于虚拟内存大于物理内存，因此如果访问到了没有映射的页面，则发生缺页中断，OS找到一个很少使用的页框将其写入磁盘，随后将缺失的页面写入内存，重新执行上次的指令。

**页表**

虚拟内存到物理地址的映射：虚拟地址被分成虚拟页号（页表索引，由页表找到页框号）与偏移量（地址字节偏量,与页框号组合形成物理地址）

**加速分页过程**

两个主要问题

- 虚拟内存到物理地址的映射必须非常快
- 如果虚拟地址空间很大，页表也会很大

每个进程都有自己的页表，因为它有自己的虚拟地址空间

​	**转换检测缓冲区TLB**

基于：大多数程序总是对少量的页面进行多次访问

加快虚拟地址到物理地址的转换

**针对大内存的页表**

- 多级页表，针对32位系统，在64位系统当中，页表过于庞大
- 倒排页表，在实际内存中，每一个页框有一个表项，而不是每一个虚拟内存有一个表项。
  - 虚拟地址到物理地址的转换较困难，无法通过索引，而必须对整个页表进行查找才能找到对应的页
  - 使用TLB解决，全局搜索使用散列表

## 分页系统地址映射

内存管理单元（MMU）管理着地址空间和物理内存的转换，其中的页表（Page table）存储着页（程序地址空间）和页框（物理内存空间）的映射表。

一个虚拟地址分成两个部分，一部分存储页面号，一部分存储偏移量。

下图的页表存放着 16 个页，这 16 个页需要用 4 个比特位来进行索引定位。例如对于虚拟地址（0010 000000000100），前 4 位是存储页面号 2，读取表项内容为（110 1），页表项最后一位表示是否存在于内存中，1 表示存在。后 12 位存储偏移量。这个页对应的页框的地址为 （110 000000000100）。

[![img](https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/cf4386a1-58c9-4eca-a17f-e12b1e9770eb.png)](https://github.com/CyC2018/CS-Notes/blob/master/docs/notes/pics/cf4386a1-58c9-4eca-a17f-e12b1e9770eb.png)

## 页面置换算法

在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘对换区中来腾出空间。

页面置换算法和缓存淘汰策略类似，可以将内存看成磁盘的缓存。在缓存系统中，缓存的大小有限，当有新的缓存到达时，需要淘汰一部分已经存在的缓存，这样才有空间存放新的缓存数据。

页面置换算法的主要目标是使页面置换频率最低（也可以说缺页率最低）。

### 1. 最佳

> OPT, Optimal replacement algorithm

所选择的被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。

是一种理论上的算法，因为无法知道一个页面多长时间不再被访问。

举例：一个系统为某进程分配了三个物理块，并有如下页面引用序列：

[![img](https://camo.githubusercontent.com/7be506554fa5a86670d2bd1f22c786ae88e0bd31/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f37efbc8c30efbc8c31efbc8c32efbc8c30efbc8c33efbc8c30efbc8c34efbc8c32efbc8c33efbc8c30efbc8c33efbc8c32efbc8c31efbc8c32efbc8c30efbc8c31efbc8c37efbc8c30efbc8c31)](https://camo.githubusercontent.com/7be506554fa5a86670d2bd1f22c786ae88e0bd31/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f37efbc8c30efbc8c31efbc8c32efbc8c30efbc8c33efbc8c30efbc8c34efbc8c32efbc8c33efbc8c30efbc8c33efbc8c32efbc8c31efbc8c32efbc8c30efbc8c31efbc8c37efbc8c30efbc8c31)

开始运行时，先将 7, 0, 1 三个页面装入内存。当进程要访问页面 2 时，产生缺页中断，会将页面 7 换出，因为页面 7 再次被访问的时间最长。

### 2. 最近最久未使用

> LRU, Least Recently Used

虽然无法知道将来要使用的页面情况，但是可以知道过去使用页面的情况。LRU 将最近最久未使用的页面换出。

为了实现 LRU，需要在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。

因为每次访问都需要更新链表，因此这种方式实现的 LRU 代价很高。

[![img](https://camo.githubusercontent.com/bb6f10172ad16d1094a12ee638783cbf3a15370a/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f34efbc8c37efbc8c30efbc8c37efbc8c31efbc8c30efbc8c31efbc8c32efbc8c31efbc8c32efbc8c36)](https://camo.githubusercontent.com/bb6f10172ad16d1094a12ee638783cbf3a15370a/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f34efbc8c37efbc8c30efbc8c37efbc8c31efbc8c30efbc8c31efbc8c32efbc8c31efbc8c32efbc8c36)

[![img](https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/eb859228-c0f2-4bce-910d-d9f76929352b.png)](https://github.com/CyC2018/CS-Notes/blob/master/docs/notes/pics/eb859228-c0f2-4bce-910d-d9f76929352b.png)

### 3. 最近未使用

> NRU, Not Recently Used

每个页面都有两个状态位：R 与 M，当页面被访问时设置页面的 R=1，当页面被修改时设置 M=1。其中 R 位会定时被清零。可以将页面分成以下四类：

- R=0，M=0
- R=0，M=1
- R=1，M=0
- R=1，M=1

当发生缺页中断时，NRU 算法随机地从类编号最小的非空类中挑选一个页面将它换出。

NRU 优先换出已经被修改的脏页面（R=0，M=1），而不是被频繁使用的干净页面（R=1，M=0）。

### 4. 先进先出

> FIFO, First In First Out

选择换出的页面是最先进入的页面。

该算法会将那些经常被访问的页面也被换出，从而使缺页率升高。

### 5. 第二次机会算法

FIFO 算法可能会把经常使用的页面置换出去，为了避免这一问题，对该算法做一个简单的修改：

当页面被访问 (读或写) 时设置该页面的 R 位为 1。需要替换的时候，检查最老页面的 R 位。如果 R 位是 0，那么这个页面既老又没有被使用，可以立刻置换掉；如果是 1，就将 R 位清 0，并把该页面放到链表的尾端，修改它的装入时间使它就像刚装入的一样，然后继续从链表的头部开始搜索。

[![img](https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/ecf8ad5d-5403-48b9-b6e7-f2e20ffe8fca.png)](https://github.com/CyC2018/CS-Notes/blob/master/docs/notes/pics/ecf8ad5d-5403-48b9-b6e7-f2e20ffe8fca.png)

### 6. 时钟

> Clock

第二次机会算法需要在链表中移动页面，降低了效率。时钟算法使用环形链表将页面连接起来，再使用一个指针指向最老的页面。

[![img](https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/5f5ef0b6-98ea-497c-a007-f6c55288eab1.png)](https://github.com/CyC2018/CS-Notes/blob/master/docs/notes/pics/5f5ef0b6-98ea-497c-a007-f6c55288eab1.png)

## 分页系统的设计

**局部分配策略与全局分配策略**

怎么样在相互竞争的可运行进程间分配内存

局部：淘汰进程中最差的页面

全局：淘汰整个内存当中最差的页面

## 分段

虚拟内存采用的是分页技术，也就是将地址空间划分成固定大小的页，每一页再与内存进行映射。

下图为一个编译器在编译过程中建立的多个表，有 4 个表是动态增长的，如果使用分页系统的一维地址空间，动态增长的特点会导致覆盖问题的出现。

[![img](https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/22de0538-7c6e-4365-bd3b-8ce3c5900216.png)](https://github.com/CyC2018/CS-Notes/blob/master/docs/notes/pics/22de0538-7c6e-4365-bd3b-8ce3c5900216.png)

分段的做法是把每个表分成段，一个段构成一个独立的地址空间。每个段的长度可以不同，并且可以动态增长。

[![img](https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/e0900bb2-220a-43b7-9aa9-1d5cd55ff56e.png)](https://github.com/CyC2018/CS-Notes/blob/master/docs/notes/pics/e0900bb2-220a-43b7-9aa9-1d5cd55ff56e.png)

## 段页式

程序的地址空间划分成多个拥有独立地址空间的段，每个段上的地址空间划分成大小相同的页。这样既拥有分段系统的共享和保护，又拥有分页系统的虚拟内存功能。

## 分页与分段的比较

- 对程序员的透明性：分页透明，但是分段需要程序员显示划分每个段。
- 地址空间的维度：分页是一维地址空间，分段是二维的。
- 大小是否可以改变：页的大小不可变，段的大小可以动态改变。
- 出现的原因：分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。

# 参考 #

1. 
